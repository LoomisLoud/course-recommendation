{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration done on the EPFL recommender system\n",
    "\n",
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql.connector as sql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Read the confidential token.\n",
    "credentials = configparser.ConfigParser()\n",
    "credentials.read('credentials.ini')\n",
    "db_connection = sql.connect(host=credentials.get('mysql', 'url'),\n",
    "                            database='semester_project_romain',\n",
    "                            user=credentials.get('mysql', 'username'),\n",
    "                            password=credentials.get('mysql', 'password'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found courses that should be removed:\n",
    "# Génie nucléaire, Ingenierie financiere:\n",
    "# useless, most courses compulsatory\n",
    "courses_to_remove = [\n",
    "    \"Admission année sup.\",\n",
    "    \"Projet de master en systèmes de communication\",\n",
    "    \"SHS : Introduction au projet\",\n",
    "    \"Cycle master\",\n",
    "    \"Projet de Master\",\n",
    "    \"Groupe Core courses & options\",\n",
    "    \"Bloc Projets et SHS\",\n",
    "    \"Groupe 2 : Options\",\n",
    "    \"Master SC\",\n",
    "    \"Mineur\",\n",
    "    \"Groupe 1\",\n",
    "    \"Projet en systèmes de communication II\",\n",
    "    \"Projet en informatique II\",\n",
    "    \"Projet de master en informatique\",\n",
    "    \"Cours réservés spécifiquement aux étudiants s'inscrivant pour le mineur Area and Cultural Studies\",\n",
    "    \"SHS : Projet\",\n",
    "    \"Optional project in communication systems\",\n",
    "    \"Optional project in computer science\",\n",
    "    \"Mineur : Neurosciences computationnelles\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Systèmes de communication)\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Informatique)\",\n",
    "    \"Cours UNIL - Faculté des hautes études commerciales HEC I (printemps)\",\n",
    "    \"Chemical engineering of heterogenous reactions\",\n",
    "    \"Process development I\",\n",
    "    \"Chemical engineering lab & project\",\n",
    "    \"Stage d'ingénieur (master en Génie chimique et Biotechnologie)\",\n",
    "    \"Projet de master en génie chimique et biotechnologie\",\n",
    "    \"Interdisciplinary project\",\n",
    "    \"Projet de master en chimie moléculaire et biologique\",\n",
    "    \"Project in molecular sciences\",\n",
    "    \"Superstudio\",\n",
    "    \"Enoncé théorique de master\",\n",
    "    \"De la structure à l'ornement\",\n",
    "    \"Projet de master en architecture\",\n",
    "    \"Pré-étude projet de master\",\n",
    "    \"Projet SIE/ENAC\",\n",
    "    \"Projet de master en sciences et ingénierie de l'environnement\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Sciences et ingénierie de l'environnement)\",\n",
    "    \"Projet de master en génie électrique et électronique\",\n",
    "    \"Projet Génie mécanique II\",\n",
    "    \"Projet Génie mécanique I\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Génie mécanique)\",\n",
    "    \"Projet de master en génie mécanique\",\n",
    "    \"Research project in materials I\",\n",
    "    \"Projet de master en science et génie des matériaux\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Science et génie des matériaux)\",\n",
    "    \"Projet microtechnique I\",\n",
    "    \"Projet de master en microtechnique\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Microtechnique)\",\n",
    "    \"Projet de master en mathématiques\",\n",
    "    \"Projet de Mathématiques (master)\",\n",
    "    \"Stage d'ingénieur (master en Ingénierie mathématique)\",\n",
    "    \"Projet de master en mathématiques\",\n",
    "    \"Projet de Mathématiques (master)\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Ingénierie mathématique)\",\n",
    "    \"Stage d'ingénieur (master en Bioingénierie)\",\n",
    "    \"Projet de master en bioingénierie et biotechnologie\",\n",
    "    \"Stage d'ingénieur (master en Sciences et technologie du vivant)\",\n",
    "    \"Projet de master en sciences et technologies du vivant\",\n",
    "    \"Stage d'ingénieur (master en Génie nucléaire)\",\n",
    "    \"Projet de master en génie nucléaire\",\n",
    "    \"Stage d'ingénieur (master en Ingénierie physique)\",\n",
    "    \"Projet de master en physique\",\n",
    "    \"Stage d'ingénieur (master en Sciences et ingénierie computationnelles)\",\n",
    "    \"Projet de master en science et ingénierie computationelles\",\n",
    "    \"Projet CSE I\",\n",
    "    \"Projet CSE II\",\n",
    "    \"Project in energy management and sustainability I\",\n",
    "    \"Stage d'ingénieur crédité avec le PDM (master en Gestion de l'énergie et construction durable)\",\n",
    "    \"Stage d'ingénieur (master en Génie électrique et électronique)\",\n",
    "]\n",
    "\n",
    "domains_to_remove = [\n",
    "    \"Humanities and social sciences\",\n",
    "    \"Programme Sciences humaines et sociales\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PlanType = \"PLAN_EXAMINE\" ?????\n",
    "all_info = \"\"\"\n",
    "            select distinct \n",
    "                PersonID, \n",
    "                PedagogicalCode, \n",
    "                StudyDomain, \n",
    "                UnitName, \n",
    "                SubjectName, \n",
    "                Course_Enrolments.SubjectID,\n",
    "                SectionName, \n",
    "                CourseCode,\n",
    "                YearName\n",
    "            from \n",
    "                Course_Enrolments\n",
    "                inner join \n",
    "                Course_Codes \n",
    "                    on Course_Codes.planid = course_enrolments.planid \n",
    "                    and Course_Codes.subjectid = course_enrolments.subjectid\n",
    "            where \n",
    "                LevelName = \"Master\"\n",
    "                and IsStudent = 1\n",
    "                and IsEnrolled = 1\n",
    "                and (YearName = \"2010-2011\"\n",
    "                or YearName = \"2011-2012\"\n",
    "                or YearName = \"2012-2013\"\n",
    "                or YearName = \"2013-2014\"\n",
    "                or YearName = \"2014-2015\"\n",
    "                or YearName = \"2015-2016\")\n",
    "                \n",
    "            \"\"\"\n",
    "#all_df = pd.read_sql(all_info, con=db_connection)\n",
    "#all_df = all_df[~all_df.SubjectName.isin(courses_to_remove)]\n",
    "# Removing the SHS courses\n",
    "#all_df = all_df[~(all_df.StudyDomain.isin(domains_to_remove))]\n",
    "#print(all_df.UnitName.unique())\n",
    "#all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PlanType = \"PLAN_EXAMINE\" ?????\n",
    "#unit_name = '(UnitName like \"%nform%\" or UnitName like \"%omm%\")'\n",
    "units = [\n",
    "    \"Génie chimique et biotechnologie\",\n",
    "    \"Chimie moléculaire et biologique\",\n",
    "    \"Informatique\",\n",
    "    \"Architecture\",\n",
    "    \"Génie civil\",\n",
    "    \"Sciences et ingénierie de l'environnement\",\n",
    "    \"Génie électrique et électronique\",\n",
    "    \"Génie mécanique\",\n",
    "    \"Science et génie des matériaux\",\n",
    "    \"Microtechnique\",\n",
    "    \"Systèmes de communication - master\",\n",
    "    \"Mathématiques - master\",\n",
    "    \"Ingénierie mathématique\",\n",
    "    \"Bioingénierie\",\n",
    "    \"Sciences et technologies du vivant - master\",\n",
    "    \"Micro and Nanotechnologies for Integrated Systems\",\n",
    "    \"Génie nucléaire\",\n",
    "    \"Ingénierie financière\",\n",
    "    \"Ingénierie physique\",\n",
    "    \"Physique - master\",\n",
    "    \"Science et ingénierie computationnelles\",\n",
    "    \"Gestion de l'énergie et construction durable\",\n",
    "    \"Management, technologie et entrepreneuriat\",\n",
    "]\n",
    "\n",
    "all_info = \"\"\"\n",
    "            select distinct \n",
    "                PersonID, \n",
    "                PedagogicalCode, \n",
    "                StudyDomain, \n",
    "                UnitName, \n",
    "                UnitID, \n",
    "                UnitCode,\n",
    "                SubjectName, \n",
    "                Course_Enrolments.SubjectID,\n",
    "                SectionName, \n",
    "                CourseCode,\n",
    "                YearName\n",
    "            from \n",
    "                Course_Enrolments\n",
    "                inner join \n",
    "                Course_Codes \n",
    "                    on Course_Codes.planid = course_enrolments.planid \n",
    "                    and Course_Codes.subjectid = course_enrolments.subjectid\n",
    "            where \n",
    "                {}\n",
    "                and LevelName = \"Master\"\n",
    "            \"\"\".format(\"UnitName = \\\"{}\\\"\".format(units[22]))\n",
    "\n",
    "all_df = pd.read_sql(all_info, con=db_connection)\n",
    "all_df = all_df[~all_df.SubjectName.isin(courses_to_remove)]\n",
    "# Removing the SHS courses\n",
    "all_df = all_df[~(all_df.StudyDomain.isin(domains_to_remove))]\n",
    "# Mapping of subject ids to subject names\n",
    "subject_mapping = all_df[['SubjectID', 'SubjectName']].drop_duplicates()\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_courses = \"\"\"\n",
    "            select distinct \n",
    "                PedagogicalCode, \n",
    "                SubjectName, \n",
    "                SubjectID,\n",
    "                StudyDomain,\n",
    "                YearName\n",
    "            from \n",
    "                Course_Enrolments \n",
    "            where \n",
    "                UnitName like \"%ommunication%\" \n",
    "                and \n",
    "                LevelName = \"Master\"\n",
    "                and left(PedagogicalCode, 2) = \"MA\"\n",
    "                and YearName = \"2015-2016\"\n",
    "            \"\"\"\n",
    "#current_courses_df = pd.read_sql(current_courses, con=db_connection)\n",
    "# These are the current courses (latest data) given in syscom @EPFL\n",
    "#current_courses_df = current_courses_df[~current_courses_df.SubjectName.isin(courses_to_remove)]\n",
    "#current_courses_df = current_courses_df[~current_courses_df.StudyDomain.isin(domains_to_remove)]\n",
    "#current_courses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "courses_matrix = all_df[['PersonID', 'SubjectName']]\n",
    "courses_matrix = courses_matrix.drop_duplicates()\n",
    "courses_matrix = courses_matrix.set_index(['PersonID', 'SubjectName'])\n",
    "\n",
    "def series_to_integers(series):\n",
    "    \"Converts a whole series to integers\"\n",
    "    return pd.to_numeric(series, downcast='integer')\n",
    "\n",
    "# If the course was taken, set it to 1\n",
    "courses_matrix['joined'] = 1\n",
    "courses_matrix = courses_matrix.reset_index().pivot(index='PersonID', columns='SubjectName', values='joined')\n",
    "courses_matrix = courses_matrix.fillna(0)\n",
    "courses_matrix = courses_matrix.apply(series_to_integers)\n",
    "\n",
    "# Removing all students that took less than five courses\n",
    "MIN_COURSES_BY_STUDENT = 10\n",
    "courses_matrix =courses_matrix[np.sum(courses_matrix == 1, axis=1) > MIN_COURSES_BY_STUDENT]\n",
    "courses_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-enrolment matrix\n",
    "## Most taken courses\n",
    "We need to find a way to get a cleaner dataset of courses, a lot of them are not usefull or outdated and should not be recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Taking a look at the most taken courses\n",
    "registrations_df = all_df.set_index(['SubjectName', 'YearName'])\n",
    "all_df_registrations = registrations_df.groupby(['SubjectName', 'YearName']).size()\n",
    "\n",
    "registrations_df['Registration'] = all_df_registrations\n",
    "registrations_df = registrations_df.reset_index()\n",
    "# Pick only courses that have a study domain (removes bullshit)\n",
    "# such as Projects and groups, minors etc\n",
    "registrations_df = registrations_df[~registrations_df.StudyDomain.isnull()]\n",
    "# Remove the SHS courses\n",
    "registrations_df = registrations_df[~(registrations_df.StudyDomain == \"Programme Sciences humaines et sociales\")]\n",
    "# Removes non important information\n",
    "registrations_df = registrations_df.drop([\n",
    "    'PersonID', \"StudyDomain\", \"SectionName\", \"PedagogicalCode\",\n",
    "    \"CourseCode\"], axis=1)\n",
    "registrations_df = registrations_df.drop_duplicates()\n",
    "registrations_df = registrations_df.set_index(['SubjectName', 'YearName']).sort_index()\n",
    "registrations = registrations_df.sort_values(ascending=False, by='Registration')\n",
    "\n",
    "# Latest data registrations\n",
    "registrations.xs('2015-2016', level='YearName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrolments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_enrolments = pd.DataFrame(data=0, columns=courses_matrix.columns, index=courses_matrix.columns)\n",
    "for row in courses_matrix.iterrows():\n",
    "    taken_courses = row[1][row[1] == 1].index.tolist()\n",
    "    for i,course in enumerate(taken_courses):\n",
    "        co_enrolments.loc[course, taken_courses[i+1:]] += 1\n",
    "    \n",
    "\n",
    "# Copy the upper triangle matrix to lower triangle one\n",
    "co_enrolments = co_enrolments + co_enrolments.T\n",
    "\n",
    "# Transforming to probabilities and removing the rows summing to nan\n",
    "co_enrolments = co_enrolments / co_enrolments.sum(axis=0)\n",
    "\n",
    "def get_coenrolment(course, other_enrolments):\n",
    "    return co_enrolments.loc[course, other_enrolments].mean()\n",
    "\n",
    "def training_weight_coenrolments(user_index):\n",
    "    courses_taken = courses_matrix.iloc[user_index][courses_matrix.iloc[user_index] == 1].index.tolist()\n",
    "    return [ get_coenrolment(c, courses_taken) for c in courses_matrix.columns.tolist() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grades correlations inbetween courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def course_id_mapper(sub_id):\n",
    "    mapped = subject_mapping[subject_mapping.SubjectID == sub_id].SubjectName\n",
    "    return mapped.values[0] if not mapped.empty else np.nan\n",
    "\n",
    "# If one of the correlations is non-existent, return the other\n",
    "def correlation_series_mean(f_corr, s_corr):\n",
    "    if f_corr == -5 and s_corr == -5: raise Exception(\"both correlations non-existent\")\n",
    "    if f_corr == -5 or s_corr == -5: return max(f_corr, s_corr)\n",
    "    return np.mean([f_corr, s_corr])\n",
    "    \n",
    "# Retrieve courses correlations\n",
    "grade_corr = pd.read_csv('data/correlation-subject-pair.csv')\n",
    "grade_corr = grade_corr[['sub1', 'sub2', \"cor1\", \"cor2\"]]\n",
    "grade_corr['cor_mean'] = grade_corr[['cor1', 'cor2']].apply(lambda x: correlation_series_mean(x[0],x[1]), axis=1)\n",
    "grade_corr = grade_corr[['sub1', 'sub2', 'cor_mean']]\n",
    "\n",
    "# Use SubjectName instead of SubjectID\n",
    "grade_corr['sub1_name'] = grade_corr.sub1.map(course_id_mapper)\n",
    "grade_corr['sub2_name'] = grade_corr.sub2.map(course_id_mapper)\n",
    "grade_corr = grade_corr.dropna()[['sub1_name', 'sub2_name', 'cor_mean']]\n",
    "\n",
    "# In case there are no correlations, we set to the mean of all of them\n",
    "mean_correlations = grade_corr.mean()\n",
    "\n",
    "# Let's make it a matrix\n",
    "grade_corr_matrix = grade_corr.set_index([\"sub1_name\", \"sub2_name\"]).unstack(level=0).fillna(mean_correlations)\n",
    "# normalize correlations by adding 1 and dividing by the max\n",
    "grade_corr_matrix = (grade_corr_matrix + 1)/2\n",
    "\n",
    "# Set not found courses correlations to the mean of all correlations\n",
    "no_corr_courses = [ c for c in courses_matrix.columns.tolist() if c not in grade_corr_matrix.index.tolist() ]\n",
    "missing_correlations = pd.DataFrame(np.full(fill_value=mean_correlations, \n",
    "                                            shape=(grade_corr_matrix.shape[0], len(no_corr_courses))), \n",
    "                                    columns=no_corr_courses, \n",
    "                                    index=grade_corr_matrix.index.tolist())\n",
    "grade_corr_matrix.columns = grade_corr_matrix.columns.droplevel()\n",
    "grade_corr_matrix = pd.concat([grade_corr_matrix, missing_correlations], axis=1)\n",
    "\n",
    "# Let's transform it into probabilistic\n",
    "grade_corr_matrix = grade_corr_matrix / grade_corr_matrix.sum(axis=0)\n",
    "\n",
    "def get_grades_corr(course, other_enrolments):\n",
    "    if course not in grade_corr_matrix.index.tolist():\n",
    "        return 1/grade_corr_matrix.shape[1]\n",
    "    return grade_corr_matrix.loc[course, other_enrolments].mean()\n",
    "\n",
    "def training_weight_grade_corr(user_index):\n",
    "    courses_taken = courses_matrix.iloc[user_index][courses_matrix.iloc[user_index] == 1].index.tolist()\n",
    "    return [ get_grades_corr(c, courses_taken) for c in courses_matrix.columns.tolist() ]\n",
    "\n",
    "# The final dataframe of courses correlations\n",
    "grade_corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    testing_set = data.applymap(lambda x: 0)\n",
    "\n",
    "    taken_courses_flat = data.stack().to_frame()\n",
    "    taken_courses_flat = taken_courses_flat[taken_courses_flat[0] == 1]\n",
    "\n",
    "    for student in taken_courses_flat.index.get_level_values('PersonID').unique():\n",
    "        courses = taken_courses_flat.loc[student]\n",
    "        for course in courses.sample(frac=0.2, replace=False).index:\n",
    "            testing_set.loc[student, course] = 1\n",
    "    training_set = data - testing_set\n",
    "\n",
    "    return training_set, testing_set\n",
    "\n",
    "training_set, testing_set = split_data(courses_matrix)\n",
    "\n",
    "# Numpify the data\n",
    "train_np = training_set.apply(axis=1, func=lambda x: x.astype(int)).as_matrix()\n",
    "test_np = testing_set.apply(axis=1, func=lambda x: x.astype(int)).as_matrix()\n",
    "\n",
    "# the indices of each user\n",
    "users = np.array(np.arange(courses_matrix.shape[0])[np.newaxis].T, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision is the percentage of recommended items that are \"good ones\"\n",
    "# Hence, the matched prediction divided by N of Top-N\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Takes predictions as an np array of indices,\n",
    "    true ratings as a numpy array,\n",
    "    returns precision\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    for i,user in enumerate(y_pred):\n",
    "        nb_right_pred = sum(y_true[i, user] == 1)\n",
    "        precisions.append(nb_right_pred / y_pred.shape[1])\n",
    "    return np.mean(precisions)\n",
    "    \n",
    "#Recall is the percentage of good ones that are recommended.\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Takes predictions as an np array of indices,\n",
    "    true ratings as a numpy array,\n",
    "    returns recall\n",
    "    \"\"\"\n",
    "    recall = []\n",
    "    for i,user in enumerate(y_pred):\n",
    "        nb_right_pred = sum(y_true[i, user] == 1)\n",
    "        recall.append(nb_right_pred / y_true[i].sum())\n",
    "    return np.mean(recall)\n",
    "    \n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Takes predictions as an np array of indices,\n",
    "    true ratings as a numpy array,\n",
    "    returns f1 score\n",
    "    \"\"\"\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return f1\n",
    "\n",
    "def mean_average_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Takes predictions as an np array of indices,\n",
    "    true ratings as a numpy array,\n",
    "    returns the mean average precision\n",
    "    \"\"\"\n",
    "    N = y_pred.shape[1]\n",
    "    average_prec = []\n",
    "    for i, user in enumerate(y_pred):\n",
    "        summed_prec = 0\n",
    "        for k in np.arange(N):\n",
    "            prec_k = sum(y_true[i, user] == 1) / N\n",
    "            rel_k = y_true[i, user[-1]]\n",
    "            summed_prec += (prec_k * rel_k)\n",
    "        average_prec.append(summed_prec / min(N, y_true[i].sum()))\n",
    "    \n",
    "    return np.mean(average_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative filtering with Collaborative Denoising Auto-Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Flatten, Dropout, Activation\n",
    "from keras.layers.merge import Add\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def create(I, U, K, hidden_activation, output_activation, q=0.5, l=0.01):\n",
    "    '''\n",
    "    create model\n",
    "    Reference:\n",
    "      Yao Wu, Christopher DuBois, Alice X. Zheng, Martin Ester.\n",
    "        Collaborative Denoising Auto-Encoders for Top-N Recommender Systems.\n",
    "          The 9th ACM International Conference on Web Search and Data Mining (WSDM'16), p153--162, 2016.\n",
    "\n",
    "    :param I: number of items\n",
    "    :param U: number of users\n",
    "    :param K: number of units in hidden layer\n",
    "    :param hidden_activation: activation function of hidden layer\n",
    "    :param output_activation: activation function of output layer\n",
    "    :param q: drop probability\n",
    "    :param l: regularization parameter of L2 regularization\n",
    "    :return: CDAE\n",
    "    :rtype: keras.models.Model\n",
    "    '''\n",
    "    x_item = Input((I,), name='x_item')\n",
    "    h_item = Dropout(q)(x_item)\n",
    "    h_item = Dense(K, kernel_regularizer=l2(l), bias_regularizer=l2(l))(h_item)\n",
    "\n",
    "    # dtype should be int to connect to Embedding layer\n",
    "    x_user = Input((1,), dtype='int32', name='x_user')\n",
    "    h_user = Embedding(input_dim=U, output_dim=K, input_length=1, embeddings_regularizer=l2(l))(x_user)\n",
    "    h_user = Flatten()(h_user)\n",
    "\n",
    "#    h = merge([h_item, h_user], mode='sum')\n",
    "    h = Add()([h_item, h_user])\n",
    "    if hidden_activation:\n",
    "        h = Activation(hidden_activation)(h)\n",
    "    y = Dense(I, activation=output_activation)(h)\n",
    "\n",
    "    return Model(inputs=[x_item, x_user], outputs=y)\n",
    "\n",
    "def success_rate(true, pred):\n",
    "    \"\"\"\n",
    "    The success rate is defined as the percentage of chances that we pick\n",
    "    one of the recommendations.\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    for i in range(pred.shape[0]):\n",
    "        t = np.where(true[i] == 1) # true set\n",
    "        ary = np.intersect1d(pred[i], t)\n",
    "        if ary.size > 0:\n",
    "            cnt += 1\n",
    "    return cnt * 100 / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_test = 0.998\n",
    "k_test = 27\n",
    "\n",
    "# model\n",
    "# Q was 0.50, now 0.998 ?\n",
    "model = create(I=train_np.shape[1], U=len(users)+1, K=k_test,\n",
    "                    hidden_activation='relu', output_activation='sigmoid', q=q_test, l=0.01)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam') \n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam') \n",
    "\n",
    "#    model.summary()\n",
    "\n",
    "# train\n",
    "history = model.fit(x=[train_np, users], y=train_np,\n",
    "                    batch_size=128, epochs=2000, verbose=2,\n",
    "                    #validation_data=[[test_np, users],\n",
    "                    #test_np])\n",
    "                    validation_split=0.20)\n",
    "\n",
    "pred = model.predict(x=[test_np, users])\n",
    "pred = pred * (train_np == 0) # remove watched items from predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_prediction(pred):\n",
    "    sorted_predictions = np.argsort(pred)\n",
    "\n",
    "    mean_aps = []\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    # Take the N best recommendations\n",
    "    N = 20\n",
    "    print(\"For k =\", k_test, \":\")\n",
    "    print(\"For q =\", q_test, \":\")\n",
    "    print(\"\\tdifference of success rates at 10 - 1:\", success_rate(test_np, sorted_predictions[:,-10:]) - success_rate(test_np, sorted_predictions[:,-1:]))\n",
    "    for n in range(1, N + 1):\n",
    "        prediction_at_n = sorted_predictions[:, -n:]\n",
    "        mean_ap = mean_average_precision(test_np, prediction_at_n)\n",
    "        mean_aps.append(mean_ap)\n",
    "        prec = precision(test_np, prediction_at_n)\n",
    "        precisions.append(prec)\n",
    "        rec = recall(test_np, prediction_at_n)\n",
    "        recalls.append(rec)\n",
    "        f1 = f1_score(test_np, prediction_at_n)\n",
    "        f1s.append(f1)\n",
    "        sr = success_rate(test_np, prediction_at_n)\n",
    "        print(\"\\n\\tSuccess Rate at {:d}: {:f}\".format(n, sr))\n",
    "        print(\"\\tMAP at {}: {}\".format(n, mean_ap))\n",
    "        print(\"\\tPrecision at {}: {}\".format(n, prec))\n",
    "        print(\"\\tRecall at {}: {}\".format(n, rec))\n",
    "        print(\"\\tF1 score at {}: {}\".format(n, f1))\n",
    "        \n",
    "    # Plotting the MAP at k\n",
    "    map_df = pd.DataFrame(mean_aps)\n",
    "    map_df.index.name = 'K'\n",
    "    map_df.rename(columns={0:'Mean average precision'}, inplace=True)\n",
    "    map_df = map_df.reset_index()\n",
    "    map_df['K'] = map_df['K'] + 1\n",
    "\n",
    "    col_pal = sns.cubehelix_palette(N, reverse=True)\n",
    "    sns.barplot(x=\"K\", y=\"Mean average precision\", data=map_df, palette=col_pal)\n",
    "    plt.title(\"Mean average precision at k for top-k courses recommendations\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    prec_rec_df = pd.DataFrame(data={\"Precision\":precisions, \"Recall\":recalls})\n",
    "    plt.plot(recalls, precisions, color='b', alpha=0.2)\n",
    "    plt.fill_between(recalls, precisions, step='post', alpha=0.2, color='b')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseline + co-enrolment\n",
    "preds = np.array([ np.array(training_weight_coenrolments(i)) * np.array(nn_weights) for i, nn_weights in enumerate(pred) ])\n",
    "print_stats_prediction(preds)\n",
    "\n",
    "# Baseline + grade correlation + co-enrolment\n",
    "preds = np.array([ np.array(training_weight_coenrolments(i)) * np.array(training_weight_grade_corr(i)) * np.array(nn_weights) for i, nn_weights in enumerate(pred) ])\n",
    "print_stats_prediction(preds)\n",
    "\n",
    "# Only baseline\n",
    "#print_stats_prediction(pred)\n",
    "\n",
    "# Only co-enrolment\n",
    "#preds = np.array([ np.array(training_weight_coenrolments(i)) for i, nn_weights in enumerate(pred) ])\n",
    "#print_stats_prediction(preds)\n",
    "\n",
    "# Only grade correlations\n",
    "#preds = np.array([ np.array(training_weight_grade_corr(i)) for i, nn_weights in enumerate(pred) ])\n",
    "#print_stats_prediction(preds)\n",
    "\n",
    "# Baseline + grade correlations\n",
    "#preds = np.array([ np.array(training_weight_grade_corr(i)) * np.array(nn_weights) for i, nn_weights in enumerate(pred) ])\n",
    "#print_stats_prediction(preds)\n",
    "\n",
    "# Grade correlations + co-enrolment\n",
    "#preds = np.array([ np.array(training_weight_coenrolments(i)) * np.array(training_weight_grade_corr(i)) for i, nn_weights in enumerate(pred) ])\n",
    "#print_stats_prediction(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into group1, group2 courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_courses = [\"Advanced algorithms\", \"Advanced computer architecture\",\n",
    "                 \"Cryptography and security\", \"Advanced databases\",\n",
    "                 \"Distributed algorithms\", \"Distributed information systems\",\n",
    "                 \"Foundations of software\", \"Information theory and coding\",\n",
    "                 \"Pattern classification and machine learning\"]\n",
    "MIN_COURSES_BY_STUDENT_group1 = 2\n",
    "MIN_COURSES_BY_STUDENT_group2 = 3\n",
    "\n",
    "group1_courses_matrix = courses_matrix[group1_courses]\n",
    "group1_courses_matrix = group1_courses_matrix[np.sum(group1_courses_matrix == 1, axis=1) > MIN_COURSES_BY_STUDENT_group1]\n",
    "group2_courses_matrix = courses_matrix.drop(group1_courses, axis=1)\n",
    "group2_courses_matrix = group2_courses_matrix[np.sum(group2_courses_matrix == 1, axis=1) > MIN_COURSES_BY_STUDENT_group2]\n",
    "\n",
    "training_set_group1, testing_set_group1 = split_data(group1_courses_matrix)\n",
    "training_set_group2, testing_set_group2 = split_data(group2_courses_matrix)\n",
    "\n",
    "# Numpify the data\n",
    "train_np_1 = training_set_group1.apply(axis=1, func=lambda x: x.astype(int)).as_matrix()\n",
    "test_np_1 = testing_set_group1.apply(axis=1, func=lambda x: x.astype(int)).as_matrix()\n",
    "train_np_2 = training_set_group2.apply(axis=1, func=lambda x: x.astype(int)).as_matrix()\n",
    "test_np_2 = testing_set_group2.apply(axis=1, func=lambda x: x.astype(int)).as_matrix()\n",
    "\n",
    "# the indices of each user\n",
    "users_group1 = np.array(np.arange(group1_courses_matrix.shape[0])[np.newaxis].T, dtype=np.int32)\n",
    "users_group2 = np.array(np.arange(group2_courses_matrix.shape[0])[np.newaxis].T, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for a student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = [ \n",
    "\"Distributed information systems\",\n",
    "\"Information theory and coding\",\n",
    "\"Pattern classification and machine learning\",\n",
    "\"Mobile networks\",\n",
    "\"Statistical signal and data processing through applications\",\n",
    "\"TCP/IP networking\",\n",
    "\"Digital education & learning analytics\"]\n",
    "my_courses = pd.DataFrame(data=0, columns=courses_matrix.columns, index=[\"Romain\"])\n",
    "my_courses[me] = 1\n",
    "taken_courses = my_courses.loc[\"Romain\"][my_courses.loc[\"Romain\"] == 1].index.tolist()\n",
    "\n",
    "my_binary_courses = my_courses.as_matrix()\n",
    "binary_courses_format = np.array([[1]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_romain = model.predict(x=[my_binary_courses, binary_courses_format])\n",
    "#preds_romain = np.array([ np.array(training_weight_coenrolments(i)) * np.array(training_weight_grade_corr(i)) * np.array(nn_weights) for i, nn_weights in enumerate(pred) ])\n",
    "#print_stats_prediction(preds)\n",
    "prediction_romain = np.argsort(prediction_romain)\n",
    "\n",
    "predicted_courses = [courses_matrix.columns[i] for i in prediction_romain[0]]\n",
    "last_year_courses = list(registrations.xs('2015-2016', level='YearName').index)\n",
    "predicted_courses = [c for c in predicted_courses if c in last_year_courses and c not in taken_courses]\n",
    "\n",
    "print(\"I picked the following courses: \\n\\t-{} \\n\\nHence we propose the following: \\n\\t-{}\"\n",
    "     .format(\"\\n\\t-\".join(taken_courses), \"\\n\\t-\".join(predicted_courses[::-1][:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done\n",
    "- All data gives really bad results (discrimination by section)\n",
    "- Results are different from one domain to another (BEFORE WEIGHING OUT THE OBLIGATORY COURSES, or courses that are bloat (laboratories etc..., case by case basis ?)\n",
    "- [They talk a bit about top-N recommendation in this paper (Boi)](http://delivery.acm.org/10.1145/2810000/2800184/p179-maksai.pdf?ip=128.179.189.64&id=2800184&acc=ACTIVE%20SERVICE&key=FC66C24E42F07228%2E7E17DDD1CCA0F75B%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=1003867347&CFTOKEN=59100520&__acm__=1510214008_777b3b2b2f3763bb6c7aa57bcdcdf49a)\n",
    "- Move to the new data\n",
    "- Right precision and recall metrics\n",
    "- Right test/train se\n",
    "- Try on like 5 sections with same parameters if still good results\n",
    "- Doing it by faculty gives same results (for IC)\n",
    "- Split options and obligatory recommendations\n",
    "- Quick hard-coded demo for taken courses\n",
    "- Co-enrolment matrix\n",
    "- Multiply probability of taking course at output with proba that a student takes the predicted course before argsort (mean of coenrolment inbetween one prediction and ALL courses the student took). Then compare baseline with new system.\n",
    "- Correlation grades used by multiply to each pair of course, and put it in the pipeline. Then compare baseline with this one\n",
    "- Try by faculty (all courses from ENAC for example, IC is not, and all good)\n",
    "- Get results by faculties, wait all results to do model selection\n",
    "\n",
    "### Questions\n",
    "\n",
    "### To do\n",
    "- Choose model based on f1 score probably\n",
    "- Differentiate inbetween metrics\n",
    "- Success rate inbetween taking one course and 2 courses\n",
    "- Co-enrolment matrix is similar to collab filtering -> map the three to one class of existing algos\n",
    "- Porting code to usable codebase for next coder ?\n",
    "- Replace names by ids from DB by production code day\n",
    "- Automatic best parameters detection ? Need a cluster ? Grid Search ?\n",
    "- start working on demo, boxes for each course and recommend stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
